{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Apriori function\n",
    "def apriori(data, min_sup):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a dictionary to store the support count for each itemset\n",
    "    support_counts = {}\n",
    "    \n",
    "    # Create a list to store frequent itemsets\n",
    "    frequent_itemsets = []\n",
    "    \n",
    "    # Create a list to store candidate itemsets\n",
    "    candidate_itemsets = []\n",
    "    \n",
    "    # Create a list to store all unique items in the dataset\n",
    "    unique_items = set([item for transaction in data for item in transaction])\n",
    "    \n",
    "    # Generate the initial set of candidate itemsets (of size 1)\n",
    "    candidate_itemsets = [frozenset([item]) for item in unique_items]\n",
    "    \n",
    "    # print(\"initiliazed. Beep Boop\")\n",
    "    cur_size = 1\n",
    "    # Loop until there are no more candidate itemsets left\n",
    "    while candidate_itemsets:\n",
    "        \n",
    "\n",
    "        # print(\"At start of candidate itemset, count is\", len(candidate_itemsets))\n",
    "        \n",
    "        # Create a dictionary to store the support count for each candidate itemset\n",
    "        candidate_support_counts = {}\n",
    "        \n",
    "        # Calculate the support count for each candidate itemset\n",
    "        bi = 0\n",
    "        mi = 0\n",
    "        si = 0\n",
    "        for transaction in data:\n",
    "            # print(\"big iteration\", bi, \"for transation\", transaction)\n",
    "            bi += 1\n",
    "            for itemset in candidate_itemsets:\n",
    "                # print(\"mid iteration\", mi, \"for itemset\", itemset)\n",
    "                mi += 1\n",
    "                if itemset.issubset(transaction):\n",
    "                    # print(\"small iteration\", si, \"itemse is subset of transaction\")\n",
    "                    if itemset in candidate_support_counts:\n",
    "                        candidate_support_counts[itemset] += 1\n",
    "                        # print(\"in support counts alread, now\", candidate_support_counts[itemset])\n",
    "                    else:\n",
    "                        candidate_support_counts[itemset] = 1\n",
    "                        # print(\"First timer, added to \", candidate_support_counts[itemset])\n",
    "        \n",
    "        # Remove candidate itemsets that do not meet the minimum support threshold\n",
    "        candidate_itemsets = [itemset for itemset in candidate_support_counts if candidate_support_counts[itemset] >= min_sup]\n",
    "        \n",
    "        # Add the remaining candidate itemsets to the list of frequent itemsets\n",
    "        frequent_itemsets.extend(candidate_itemsets)\n",
    "        \n",
    "        # Store the support count for each frequent itemset\n",
    "        for itemset in candidate_itemsets:\n",
    "            support_counts[itemset] = candidate_support_counts[itemset]\n",
    "        \n",
    "        # print(\"Current itemsets\", candidate_itemsets)\n",
    "        # Generate the next set of candidate itemsets (by joining the frequent itemsets)\n",
    "        candidate_itemsets = set()\n",
    "        for i in range(len(frequent_itemsets)):\n",
    "            for j in range(i+1, len(frequent_itemsets)):\n",
    "                itemset1 = frequent_itemsets[i]\n",
    "                # print(\"itemset 1 is\", itemset1)\n",
    "                itemset2 = frequent_itemsets[j]\n",
    "                # print(\"itemset 2 is\", itemset2)\n",
    "                union = itemset1.union(itemset2)\n",
    "                # print(\"uniion is\", union)\n",
    "                if len(union) == cur_size + 1 and union not in candidate_itemsets:\n",
    "                    # print(\"it was decided that they are the same size\")\n",
    "                    candidate_itemsets.add(union)\n",
    "        # print(\"Next itemsets\", candidate_itemsets)\n",
    "        cur_size += 1\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > 2:\n",
    "            print(\"Time is greater than 2 seconds!\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "    # Return the frequent itemsets and their support counts\n",
    "    return frequent_itemsets, support_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'milk'}) 4\n",
      "frozenset({'bread'}) 4\n",
      "frozenset({'beer'}) 3\n",
      "frozenset({'diapers'}) 4\n",
      "frozenset({'milk', 'bread'}) 3\n",
      "frozenset({'beer', 'diapers'}) 3\n",
      "frozenset({'diapers', 'bread'}) 3\n",
      "frozenset({'diapers', 'milk'}) 3\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "transactions = [\n",
    "    [\"bread\", \"milk\"],\n",
    "    [\"bread\", \"diapers\", \"beer\", \"eggs\"],\n",
    "    [\"milk\", \"diapers\", \"beer\", \"cola\"],\n",
    "    [\"bread\", \"milk\", \"diapers\", \"beer\"],\n",
    "    [\"bread\", \"milk\", \"diapers\", \"cola\"]\n",
    "]\n",
    "min_sup = 3\n",
    "\n",
    "frequent_itemsets, support_counts = apriori(transactions, min_sup)\n",
    "\n",
    "# Print the frequent itemsets and their support counts\n",
    "for itemset in frequent_itemsets:\n",
    "    print(itemset, support_counts[itemset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'beer'}) => frozenset({'diapers'}): 1.0\n"
     ]
    }
   ],
   "source": [
    "min_conf = 0.8\n",
    "\n",
    "# Find and print association rules that meet minimum confidence\n",
    "for itemset in frequent_itemsets:\n",
    "    for item in itemset:\n",
    "        antecedent = frozenset([item])\n",
    "        consequent = itemset - antecedent\n",
    "        if len(consequent) > 0:\n",
    "            rule_conf = support_counts[itemset] / support_counts[antecedent]\n",
    "            if rule_conf >= min_conf:\n",
    "                print(f\"{antecedent} => {consequent}: {rule_conf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
