{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advait Deochakke\n",
    "#Lab 1 - Web Mining \n",
    "#Inverted Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for Lab 1 of CSE3024 - Web Mining\n",
    "\n",
    "by Advait Deochakke - 20BCE1143\n",
    "\n",
    "Inverted Indices and Incidence Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import OS and String libraries to go through the files,\n",
    "\n",
    "\n",
    "and work with the documents under each folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are functions written to generalize getting the inverted indices for all documents in a folder\n",
    "\n",
    "\n",
    "Our function not only gets the occurence, but also the line number in that document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_inverted_index(folder_path):\n",
    "    # Initialize an empty dictionary to store the inverted index\n",
    "    inverted_index = {}\n",
    "\n",
    "    # Iterate over the files in the \"q1\" folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Open the file\n",
    "        with open(os.path.join(folder_path, filename), 'r') as f:\n",
    "            # Read the contents of the file into a list of lines\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Iterate over the lines in the file\n",
    "        for line_number, line in enumerate(lines):\n",
    "            # Split the line into a list of words\n",
    "            words = line.split()\n",
    "\n",
    "            # Iterate over the words in the line\n",
    "            for word in words:\n",
    "                # Normalize the word (lowercase and remove punctuation)\n",
    "                normalized_word = word.lower().strip(string.punctuation)\n",
    "\n",
    "                # If the word is not in the inverted index, add it and set its value to an empty dictionary\n",
    "                if normalized_word not in inverted_index:\n",
    "                    inverted_index[normalized_word] = {}\n",
    "\n",
    "                # If the file is not in the dictionary for this word, add it and set its value to an empty list\n",
    "                if filename not in inverted_index[normalized_word]:\n",
    "                    inverted_index[normalized_word][filename] = []\n",
    "\n",
    "                # Add the line number to the list of line numbers for this word and file\n",
    "                inverted_index[normalized_word][filename].append(line_number)\n",
    "    return inverted_index\n",
    "\n",
    "def print_inverted_index(inverted_index):\n",
    "    # Iterate over the items in the inverted index\n",
    "    for word, line_numbers in inverted_index.items():\n",
    "        # Print the word and the line numbers it appears on\n",
    "        print(f\"{word}: {line_numbers}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the code for Incidence Matrices\n",
    "\n",
    "We use the generated ivnerted index to get the incidence matrix\n",
    "\n",
    "Then print it with justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_incidence_matrix(inverted_index):\n",
    "    # Create an empty list of lists to store the matrix\n",
    "    matrix = []\n",
    "\n",
    "    # Get the list of documents from the inverted index\n",
    "    documents = []\n",
    "    for line_numbers_by_document in inverted_index.values():\n",
    "        documents += list(line_numbers_by_document.keys())\n",
    "    documents = list(set(documents))\n",
    "\n",
    "    # Add the file names as the first row of the matrix\n",
    "    matrix.append([\"\"] + list(documents))\n",
    "\n",
    "    # Iterate over the items in the inverted index\n",
    "    for word, line_numbers_by_document in inverted_index.items():\n",
    "        # Initialize an empty list to store the row for this word\n",
    "        row = [word]\n",
    "\n",
    "        # Iterate over the documents\n",
    "        for document in documents:\n",
    "            # If the word appears in the document, add a 1 to the row\n",
    "            if document in line_numbers_by_document:\n",
    "                row.append(1)\n",
    "            # If the word does not appear in the document, add a 0 to the row\n",
    "            else:\n",
    "                row.append(0)\n",
    "\n",
    "        # Add the row to the matrix\n",
    "        matrix.append(row)\n",
    "    return matrix\n",
    "\n",
    "def print_incidence_matrix(matrix):\n",
    "    # Determine the maximum length of the values in each column\n",
    "    column_widths = [max(len(str(row[i])) for row in matrix) for i in range(len(matrix[0]))]\n",
    "\n",
    "    # Print the matrix\n",
    "    for row in matrix:\n",
    "        print(\" \".join(str(x).ljust(width) for x, width in zip(row, column_widths)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have consolidatory code, to wrap everything in a nice package\n",
    "\n",
    "We also add the code for the boolean queries into the incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_and_print_both(folder_path):\n",
    "    inverted_index = build_inverted_index(folder_path=folder_path)\n",
    "    matrix = build_incidence_matrix(inverted_index)\n",
    "    print(\"inverted index for \"+ folder_path)\n",
    "    print_inverted_index(inverted_index)\n",
    "    print(\"\\nincidence matrix for \" + folder_path)\n",
    "    print_incidence_matrix(matrix)\n",
    "    print(\"\\n\\n\")\n",
    "    return matrix\n",
    "\n",
    "def boolean_query(matrix, words, operator):\n",
    "    # Handle the \"NOT\" operator separately\n",
    "    if operator == \"NOT\":\n",
    "        # Initialize an empty list to store the results\n",
    "        results = []\n",
    "\n",
    "        # Iterate over the rows of the matrix\n",
    "        for row in matrix:\n",
    "            # If the row corresponds to one of the words in the query, get the list of documents that do not contain the word\n",
    "            if row[0] in words:\n",
    "                documents = [i for i, x in enumerate(row[1:]) if x == 0]\n",
    "                # Union the results with the list of documents\n",
    "                results = list(set(results).union(documents))\n",
    "\n",
    "        # Return the results\n",
    "        return results\n",
    "\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    # Iterate over the rows of the matrix\n",
    "    for row in matrix:\n",
    "        # If the row corresponds to one of the words in the query\n",
    "        if row[0] in words:\n",
    "            # Get the list of documents that contain the word\n",
    "            documents = [i for i, x in enumerate(row[1:]) if x == 1]\n",
    "\n",
    "            # If this is the first row, set the results to the list of documents\n",
    "            if not results:\n",
    "                results = documents\n",
    "            # If the operator is \"AND\", intersect the results with the list of documents\n",
    "            elif operator == \"AND\":\n",
    "                results = list(set(results).intersection(documents))\n",
    "            # If the operator is \"OR\", union the results with the list of documents\n",
    "            elif operator == \"OR\":\n",
    "                results = list(set(results).union(documents))\n",
    "\n",
    "    # Return the results\n",
    "    return results\n",
    "\n",
    "def print_part_three(q2matrix):    \n",
    "    print(\"schizophrenia AND drug :\", end=\" \")\n",
    "    print(boolean_query(q2matrix, [\"schizophrenia\", \"drug\"], \"AND\"))\n",
    "\n",
    "    print(\"hope OR breakthrough :\", end=\" \")\n",
    "    print(boolean_query(q2matrix, [\"hope\", \"breakthrough\"], \"OR\"))\n",
    "\n",
    "    # Compute the result of the query 'word2 OR word3'\n",
    "    or_result = boolean_query(q2matrix, [\"drug\", \"approach\"], \"OR\")\n",
    "\n",
    "    # Compute the result of the query 'NOT (word2 OR word3)' by negating the result\n",
    "    not_result = [i for i in range(len(q2matrix[0])) if i not in or_result]\n",
    "\n",
    "    # Compute the final result by intersecting the result of the query 'word1 AND NOT (word2 OR word3)' with the result of the query 'NOT (word2 OR word3)'\n",
    "    and_result = boolean_query(q2matrix, [\"for\"], \"AND\")\n",
    "    final_result = list(set(and_result).intersection(not_result))\n",
    "\n",
    "    # Print the final result\n",
    "    print(\"for AND NOT (drug OR approach) :\", end=\" \")\n",
    "    print(final_result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the execution for the code, using the directories q1 and q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted index for q1\n",
      "new: {'doc1.txt': [0], 'doc4.txt': [0]}\n",
      "home: {'doc1.txt': [0], 'doc2.txt': [0], 'doc3.txt': [0], 'doc4.txt': [0]}\n",
      "sales: {'doc1.txt': [0], 'doc2.txt': [0], 'doc3.txt': [0], 'doc4.txt': [0]}\n",
      "top: {'doc1.txt': [0]}\n",
      "forecasts: {'doc1.txt': [0]}\n",
      "rise: {'doc2.txt': [0], 'doc4.txt': [0]}\n",
      "in: {'doc2.txt': [0], 'doc3.txt': [0, 0]}\n",
      "july: {'doc2.txt': [0], 'doc3.txt': [0], 'doc4.txt': [0]}\n",
      "increase: {'doc3.txt': [0]}\n",
      "\n",
      "incidence matrix for q1\n",
      "          doc1.txt doc4.txt doc3.txt doc2.txt\n",
      "new       1        1        0        0       \n",
      "home      1        1        1        1       \n",
      "sales     1        1        1        1       \n",
      "top       1        0        0        0       \n",
      "forecasts 1        0        0        0       \n",
      "rise      0        1        0        1       \n",
      "in        0        0        1        1       \n",
      "july      0        1        1        1       \n",
      "increase  0        0        1        0       \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "#part A\n",
    "q1matrix = build_and_print_both('q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted index for q2\n",
      "breakthrough: {'doc1.txt': [0]}\n",
      "drug: {'doc1.txt': [0], 'doc2.txt': [0]}\n",
      "for: {'doc1.txt': [0], 'doc3.txt': [0], 'doc4.txt': [0]}\n",
      "schizophrenia: {'doc1.txt': [0], 'doc2.txt': [0], 'doc3.txt': [0], 'doc4.txt': [0]}\n",
      "new: {'doc2.txt': [0], 'doc3.txt': [0], 'doc4.txt': [0]}\n",
      "approach: {'doc3.txt': [0]}\n",
      "treatment: {'doc3.txt': [0]}\n",
      "of: {'doc3.txt': [0]}\n",
      "hopes: {'doc4.txt': [0]}\n",
      "patients: {'doc4.txt': [0]}\n",
      "\n",
      "incidence matrix for q2\n",
      "              doc1.txt doc4.txt doc3.txt doc2.txt\n",
      "breakthrough  1        0        0        0       \n",
      "drug          1        0        0        1       \n",
      "for           1        1        1        0       \n",
      "schizophrenia 1        1        1        1       \n",
      "new           0        1        1        1       \n",
      "approach      0        0        1        0       \n",
      "treatment     0        0        1        0       \n",
      "of            0        0        1        0       \n",
      "hopes         0        1        0        0       \n",
      "patients      0        1        0        0       \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#part B\n",
    "q2matrix = build_and_print_both('q2')\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schizophrenia AND drug : [0, 3]\n",
      "hope OR breakthrough : [0]\n",
      "for AND NOT (drug OR approach) : [1]\n"
     ]
    }
   ],
   "source": [
    "print_part_three(q2matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0d6594433084cd1bb5a549db274453b5dd11eb10732a60b25ff2cc5e7735165"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
